# üèÜ betterSearch Hackathon Demo Script
## Gemini 3 + Graphon AI Hackathon

---

## üéØ **DEMO THEME: "From Zero to Knowledge Mastery in 7 Minutes"**

**Hook**: "What if you could upload 1000 pages of research papers, hours of lecture videos, and PDF textbooks‚Äîthen ask questions and get answers with exact citations? That's what we built."

---

## üìã **DEMO FLOW (7 Minutes Total)**

### **1. OPENING (30 seconds) - "The Problem"**
**Say:**
> "Students and researchers are drowning in information. You have lecture videos, research papers, PDFs, textbooks‚Äîbut no way to actually search and reason across them all. We built betterSearch: a multimodal AI knowledge base that combines Gemini 3's native multimodality with Graphon AI's trillion-token knowledge graphs."

**Visual**: Show empty interface, then demonstrate the problem with stacked documents.

---

### **2. MULTIMODAL UPLOAD (1 minute) - Graphon Track Highlight üß†**

**Say:**
> "First, let's build your knowledge graph. Watch this‚Äîwe're uploading multiple file types simultaneously: PDFs, videos, images. This is powered by Graphon AI's cross-modal architecture."

**DO:**
1. Click "Upload to Knowledge Graph" (or paperclip icon)
2. Select multiple files:
   - 2-3 PDF research papers (100+ pages total)
   - 1 lecture video (if available)
   - Screenshots/images with diagrams
3. Show the upload progress
4. **Highlight**: "Graphon is building a relationship graph across all these modalities in real-time"

**Key Points:**
- ‚úÖ **Graphon Track Prize**: Emphasize this is exactly the "best multimodal search tool"
- ‚úÖ Show cross-modal indexing (video timestamps, PDF pages, image extraction)
- ‚úÖ Mention: "This runs securely, with persistent memory that never runs out of space"

---

### **3. NATIVE MULTIMODAL QUERY (1.5 minutes) - Gemini 3 Power üîπ**

**Say:**
> "Now the magic. Gemini 3 was trained natively on text, images, audio, and video together. So when I ask a question, it reasons across ALL my sources simultaneously."

**DO:**
1. Enable "Knowledge Graph Mode" (toggle in settings/command palette)
2. Ask a complex question that requires cross-modal reasoning:
   - Example: *"Based on the lecture video and the research paper, explain how transformer attention works and show me the relevant diagrams"*
3. Show the answer streaming in
4. **Highlight the citations**:
   - üé• Video: "Lecture 3, 12:34-15:20"
   - üìÑ PDF: "Attention Paper, Page 47"
   - üñºÔ∏è Image: "Diagram from Slide 12"

**Key Points:**
- ‚úÖ Native multimodality (not just RAG stitching)
- ‚úÖ Citations with exact timestamps/page numbers
- ‚úÖ Cross-modal reasoning (video + paper + diagrams together)

---

### **4. LONG-CONTEXT DEMONSTRATION (1 minute) - 1M Token Context üîπ**

**Say:**
> "Gemini 3 has 1M token context‚Äîthat's ~700K words. We're putting that to work. Let me show you what happens when you've ingested your entire course."

**DO:**
1. Show the "Neural Archives" (Notes modal)
2. Show accumulated notes/syllabus generated from the knowledge base
3. Demonstrate a query that requires reasoning across the entire corpus:
   - Example: *"Compare the approaches to neural networks across all three papers I uploaded"*
4. Show how it synthesizes from multiple long documents

**Key Points:**
- ‚úÖ 1M token context = entire codebases/weeks of lectures
- ‚úÖ Persistent memory via Graphon (trillion-token capability)
- ‚úÖ Research/legal/finance use case

---

### **5. GENERATIVE UI & VISUALIZATION (1.5 minutes) - Gemini 3 Feature üîπ**

**Say:**
> "Gemini 3 doesn't just answer‚Äîit generates complete interactive visualizations. Watch this."

**DO:**
1. Ask: *"Visualize the architecture of the neural network from the paper"*
2. Show Mermaid diagram auto-generating
3. Click to open full-screen SVG modal
4. Ask: *"Create a flowchart of the research methodology"*
5. Show another diagram generating

**Bonus - Generative Assessment:**
1. Open Syllabus modal
2. Click on a topic
3. Click "Generate Assessment"
4. Show AI-generated MCQ quiz appearing

**Key Points:**
- ‚úÖ Generative UI (not just text responses)
- ‚úÖ Interactive visualizations (Mermaid + SVG)
- ‚úÖ Educational simulations (assessments)

---

### **6. RESEARCH AGENT - Multi-Step Reasoning (1 minute) üîπ**

**Say:**
> "For complex questions, we deploy a research agent that orchestrates multiple tools: web search, knowledge graph queries, and synthesis."

**DO:**
1. Enable "Deep Research" mode (or show command palette option)
2. Ask a question requiring external + internal knowledge:
   - Example: *"What's the latest research on attention mechanisms, and how does it compare to what's in my uploaded papers?"*
3. Show the agent planning steps:
   - Step 1: "Searching web for latest research..."
   - Step 2: "Querying knowledge graph for internal papers..."
   - Step 3: "Synthesizing findings..."
4. Show the final comprehensive answer

**Key Points:**
- ‚úÖ Multi-agent orchestration
- ‚úÖ Tool integration (web + graphon)
- ‚úÖ Reasoning workflows

---

### **7. SOCRATIC MODE - Unique Feature (30 seconds)**

**Say:**
> "And here's something unique: Socratic Mode. Instead of giving answers, the AI guides you through questioning. Perfect for deep learning."

**DO:**
1. Switch to Socratic Mode (toggle `?`)
2. Ask: *"How does backpropagation work?"*
3. Show how it asks questions back instead of answering directly
4. Mention: "This forces you to reason, not just consume"

---

### **8. CLOSING (30 seconds) - "What We Built"**

**Say:**
> "We've combined:
> - **Gemini 3's native multimodality** for cross-modal reasoning
> - **1M token context** for entire knowledge bases
> - **Generative UI** for visualizations and assessments
> - **Graphon AI** for persistent, trillion-token knowledge graphs
> - **Research agents** for multi-step reasoning
> 
> This couldn't have existed six months ago. It's the future of research and education."

**Visual**: Show a final impressive view with:
- Knowledge graph active
- Multiple visualizations
- Assessment generated
- Citations visible

---

## üéØ **KEY WINNING POINTS TO EMPHASIZE**

### **For Graphon Track ($1,000 prize):**
- ‚úÖ **Multimodal search tool**: Cross-modal search across video, audio, images, documents
- ‚úÖ **Trillion-token context**: Persistent memory that never runs out
- ‚úÖ **Secure deployment**: Runs in your environment
- ‚úÖ **Relationship-based reasoning**: Beyond transformers

### **For Main Prizes:**
- ‚úÖ **Full-codebase agents**: Reason across entire knowledge bases
- ‚úÖ **Multimodal pipelines**: Video ‚Üí documentation, PDFs ‚Üí visualizations
- ‚úÖ **Generative UI**: Interactive diagrams, assessments, schematics
- ‚úÖ **Long-context applications**: Legal, research, finance use cases

### **Technical Innovation:**
- ‚úÖ Native multimodality (not RAG hacks)
- ‚úÖ Multi-model orchestration (Gemini 3 + Graphon)
- ‚úÖ Local-first privacy (AlaSQL)
- ‚úÖ Real-time streaming responses
- ‚úÖ Socratic teaching mode (unique)

---

## üõ†Ô∏è **PRE-DEMO CHECKLIST**

### **Setup (Before Demo):**
- [ ] Pre-upload diverse files:
  - 2-3 PDF research papers (make them impressive‚ÄîML/AI papers)
  - 1 lecture video (if available)
  - Screenshots/diagrams
- [ ] Pre-generate syllabus from notes (have it ready)
- [ ] Test Graphon connection (ensure backend is running)
- [ ] Have example queries ready:
  - Cross-modal query (video + PDF)
  - Long-context query (across all docs)
  - Visualization request
  - Research agent query
- [ ] Test visualization generation (know which prompts trigger diagrams)
- [ ] Clear any errors/set API keys

### **Technical Setup:**
```bash
# Start backend (Graphon bridge)
cd backend && python server.py

# Start frontend
npm run dev

# Verify Graphon API key is set
# Check .env files
```

### **Backup Plans:**
- If Graphon fails: Show local knowledge graph mode with notes
- If upload is slow: Pre-upload before demo starts
- If visualization doesn't work: Have a pre-generated diagram ready
- If live demo crashes: Have a video recording as backup

---

## üé§ **DELIVERY TIPS**

1. **Energy**: Be excited! This is genuinely impressive tech.
2. **Pacing**: Don't rush‚Äî7 minutes is plenty if you're smooth.
3. **Visuals**: Point to screen elements as you talk.
4. **Confidence**: You built something that couldn't exist 6 months ago.
5. **Connect to themes**: Explicitly mention hackathon keywords:
   - "Native multimodality"
   - "1M token context"
   - "Generative UI"
   - "Trillion-token knowledge graphs"
   - "Cross-modal search"

---

## üìä **DEMO METRICS TO SHOW (If Time)**

- Number of documents indexed: "We just indexed 1,200 pages in 30 seconds"
- Cross-modal citations: "This answer drew from 3 PDFs, 1 video, and 2 images"
- Token context: "We're maintaining context across 500K tokens"
- Response time: "Answers with citations in under 3 seconds"

---

## üèÜ **PRIZE PITCHES**

### **Graphon Track ($1,000):**
> "We built the **definitive multimodal search tool** using Graphon. It's not just search‚Äîit's relationship-based reasoning across video, audio, images, and documents. This is what Graphon's trillion-token architecture enables."

### **Grand Prize ($50K Credits):**
> "This showcases all of Gemini 3's breakthrough capabilities: native multimodality, 1M token context, and generative UI. It's a complete platform that transforms how students and researchers interact with knowledge."

### **Antigravity Track ($25K Credits):**
> "Our research agent demonstrates multi-step reasoning and tool orchestration‚Äîexactly what Antigravity enables. We're building agents that reason across entire knowledge bases."

---

## üí° **ELEVATOR PITCH (30 seconds)**

> "We built betterSearch: the first AI knowledge base that combines Gemini 3's native multimodality with Graphon's trillion-token knowledge graphs. Upload thousands of pages of PDFs, hours of videos, and images‚Äîthen ask questions and get answers with exact citations. It generates visualizations, creates assessments, and even teaches you through Socratic questioning. This is what becomes possible when you combine the best of Gemini 3 and Graphon AI."

---

## üé¨ **FINAL DEMO STRUCTURE (Quick Reference)**

```
0:00 - Opening hook
0:30 - Multimodal upload (Graphon) ‚≠ê
1:30 - Native multimodal query (Gemini 3) ‚≠ê
3:00 - Long-context demo (1M tokens) ‚≠ê
4:00 - Generative UI (visualizations) ‚≠ê
5:30 - Research agent (multi-step) ‚≠ê
6:30 - Socratic mode (unique feature)
7:00 - Closing + impact
```

**Total: 7 minutes**

---

**GOOD LUCK! üöÄ**
